From e19333b57fbb2f55c898bbf3c8235638264cbbf2 Mon Sep 17 00:00:00 2001
From: Ryan Blue <blue@apache.org>
Date: Wed, 26 Aug 2015 14:03:39 -0700
Subject: [PATCH 099/115] KITE-1066: Fix findbugs issues.

---
 .../AbstractCombineFileRecordReader.java           |   17 ++++++++++----
 .../AbstractKiteCombineFileInputFormat.java        |   22 ++++++++++++++++---
 .../data/spi/filesystem/CSVInputFormat.java        |   10 ++++++++-
 .../data/spi/filesystem/JSONInputFormat.java       |   10 ++++++++-
 4 files changed, 48 insertions(+), 11 deletions(-)

diff --git a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractCombineFileRecordReader.java b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractCombineFileRecordReader.java
index 0aae66a..6813002 100644
--- a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractCombineFileRecordReader.java
+++ b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractCombineFileRecordReader.java
@@ -20,6 +20,7 @@ import org.apache.hadoop.mapreduce.TaskAttemptContext;
 import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;
 import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
 import org.apache.hadoop.mapreduce.lib.input.FileSplit;
+import org.kitesdk.data.DatasetOperationException;
 
 /**
  * Base class for wrapping file-based record readers with CombineFileInputFormat functionality. This allows multiple
@@ -49,11 +50,17 @@ abstract class AbstractCombineFileRecordReader<K, V> extends RecordReader<K, V>
     if (delegate != null) {
       delegate.close();
     }
-    CombineFileSplit combineSplit = (CombineFileSplit) split;
-    FileSplit fileSplit = new FileSplit(combineSplit.getPath(idx), combineSplit.getOffset(idx),
-        combineSplit.getLength(idx), combineSplit.getLocations());
-    delegate = getInputFormat().createRecordReader(fileSplit, context);
-    delegate.initialize(fileSplit, context);
+    if (split instanceof CombineFileSplit) {
+      CombineFileSplit combineSplit = (CombineFileSplit) split;
+      FileSplit fileSplit = new FileSplit(combineSplit.getPath(idx), combineSplit.getOffset(idx),
+          combineSplit.getLength(idx), combineSplit.getLocations());
+      delegate = getInputFormat().createRecordReader(fileSplit, context);
+      delegate.initialize(fileSplit, context);
+    } else {
+      throw new DatasetOperationException(
+          "Split is not a CombineFileSplit: %s:%s",
+          split.getClass().getCanonicalName(), split);
+    }
   }
 
   @Override
diff --git a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractKiteCombineFileInputFormat.java b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractKiteCombineFileInputFormat.java
index 231efa2..7656665 100644
--- a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractKiteCombineFileInputFormat.java
+++ b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/AbstractKiteCombineFileInputFormat.java
@@ -26,6 +26,7 @@ import org.apache.hadoop.mapreduce.TaskAttemptContext;
 import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;
 import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;
 import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;
+import org.kitesdk.data.DatasetOperationException;
 
 /**
  * A Kite-specific subclass of CombineFileInputFormat and CombineFileRecordReader to work around the fact that
@@ -89,15 +90,28 @@ abstract class AbstractKiteCombineFileInputFormat<K, V> extends CombineFileInput
 
     @Override
     public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {
-      KiteCombineFileSplit kiteCombineFileSplit = (KiteCombineFileSplit) split;
-      super.initialize(kiteCombineFileSplit.getCombineFileSplit(), context);
+      if (split instanceof KiteCombineFileSplit) {
+        KiteCombineFileSplit kiteCombineFileSplit = (KiteCombineFileSplit) split;
+        super.initialize(kiteCombineFileSplit.getCombineFileSplit(), context);
+      } else {
+        throw new DatasetOperationException(
+            "Split is not a KiteCombineFileSplit: %s:%s",
+            split.getClass().getCanonicalName(), split);
+      }
     }
   }
 
   @SuppressWarnings("unchecked")
   @Override
-  public RecordReader<K, V> createRecordReader(InputSplit inputSplit, TaskAttemptContext taskContext) throws IOException {
-    return new KiteCombineFileRecordReader((KiteCombineFileSplit) inputSplit, taskContext, getRecordReaderClass());
+  public RecordReader<K, V> createRecordReader(InputSplit split, TaskAttemptContext taskContext) throws IOException {
+    if (split instanceof KiteCombineFileSplit) {
+      return new KiteCombineFileRecordReader(
+          (KiteCombineFileSplit) split, taskContext, getRecordReaderClass());
+    } else {
+      throw new DatasetOperationException(
+          "Split is not a KiteCombineFileSplit: %s:%s",
+          split.getClass().getCanonicalName(), split);
+    }
   }
 
   @Override
diff --git a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/CSVInputFormat.java b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/CSVInputFormat.java
index 1aad126..319a906 100644
--- a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/CSVInputFormat.java
+++ b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/CSVInputFormat.java
@@ -28,6 +28,7 @@ import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
 import org.apache.hadoop.mapreduce.lib.input.FileSplit;
 import org.kitesdk.compat.Hadoop;
 import org.kitesdk.data.DatasetDescriptor;
+import org.kitesdk.data.DatasetOperationException;
 import org.kitesdk.data.View;
 import org.kitesdk.data.spi.AbstractRefinableView;
 import org.kitesdk.data.spi.DataModelUtil;
@@ -58,7 +59,14 @@ class CSVInputFormat<E> extends FileInputFormat<E, Void> {
       throws IOException, InterruptedException {
     Configuration conf = Hadoop.TaskAttemptContext
         .getConfiguration.invoke(context);
-    Path path = ((FileSplit) split).getPath();
+    Path path;
+    if (split instanceof FileSplit) {
+      path = ((FileSplit) split).getPath();
+    } else {
+      throw new DatasetOperationException(
+          "Split is not a FileSplit: %s:%s",
+          split.getClass().getCanonicalName(), split);
+    }
     CSVFileReader<E> reader = new CSVFileReader<E>(
         path.getFileSystem(conf), path, descriptor, accessor);
     reader.initialize();
diff --git a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/JSONInputFormat.java b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/JSONInputFormat.java
index a72ea1b..82d3075 100644
--- a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/JSONInputFormat.java
+++ b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/JSONInputFormat.java
@@ -28,6 +28,7 @@ import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
 import org.apache.hadoop.mapreduce.lib.input.FileSplit;
 import org.kitesdk.compat.Hadoop;
 import org.kitesdk.data.DatasetDescriptor;
+import org.kitesdk.data.DatasetOperationException;
 import org.kitesdk.data.View;
 import org.kitesdk.data.spi.AbstractRefinableView;
 import org.kitesdk.data.spi.DataModelUtil;
@@ -56,7 +57,14 @@ class JSONInputFormat<E> extends FileInputFormat<E, Void> {
       throws IOException, InterruptedException {
     Configuration conf = Hadoop.TaskAttemptContext
         .getConfiguration.invoke(context);
-    Path path = ((FileSplit) split).getPath();
+    Path path;
+    if (split instanceof FileSplit) {
+      path = ((FileSplit) split).getPath();
+    } else {
+      throw new DatasetOperationException(
+          "Split is not a FileSplit: %s:%s",
+          split.getClass().getCanonicalName(), split);
+    }
     JSONFileReader<E> reader = new JSONFileReader<E>(
         path.getFileSystem(conf), path, accessor);
     reader.initialize();
-- 
1.7.0.4

