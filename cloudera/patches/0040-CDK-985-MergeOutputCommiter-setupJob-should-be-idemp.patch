From f457f674869beb1515214c3c09095dfca5f5a674 Mon Sep 17 00:00:00 2001
From: Joey Echeverria <joey42@gmail.com>
Date: Tue, 14 Apr 2015 20:47:42 -0500
Subject: [PATCH 040/140] CDK-985: MergeOutputCommiter#setupJob() should be
 idempotent

* CDK-985: Fix for hadoop-1 compat
* CDK-985: More hadoop-1 compat
---
 .../data/mapreduce/DatasetKeyOutputFormat.java     |   22 +++++-
 .../data/mapreduce/TestMergeOutputCommitter.java   |   75 ++++++++++++++++++++
 .../src/main/java/org/kitesdk/compat/Hadoop.java   |   18 ++++-
 3 files changed, 111 insertions(+), 4 deletions(-)
 create mode 100644 kite-data/kite-data-mapreduce/src/test/java/org/kitesdk/data/mapreduce/TestMergeOutputCommitter.java

diff --git a/kite-data/kite-data-mapreduce/src/main/java/org/kitesdk/data/mapreduce/DatasetKeyOutputFormat.java b/kite-data/kite-data-mapreduce/src/main/java/org/kitesdk/data/mapreduce/DatasetKeyOutputFormat.java
index 4d23cbf..6a215c1 100644
--- a/kite-data/kite-data-mapreduce/src/main/java/org/kitesdk/data/mapreduce/DatasetKeyOutputFormat.java
+++ b/kite-data/kite-data-mapreduce/src/main/java/org/kitesdk/data/mapreduce/DatasetKeyOutputFormat.java
@@ -41,6 +41,7 @@ import org.kitesdk.data.PartitionStrategy;
 import org.kitesdk.data.TypeNotFoundException;
 import org.kitesdk.data.View;
 import org.kitesdk.data.spi.AbstractDataset;
+import org.kitesdk.data.spi.Compatibility;
 import org.kitesdk.data.spi.Constraints;
 import org.kitesdk.data.spi.DataModelUtil;
 import org.kitesdk.data.spi.DatasetRepositories;
@@ -355,7 +356,7 @@ public class DatasetKeyOutputFormat<E> extends OutputFormat<E, Void> {
   static class MergeOutputCommitter<E> extends OutputCommitter {
     @Override
     public void setupJob(JobContext jobContext) {
-      createJobDataset(jobContext);
+      loadOrCreateJobDataset(jobContext);
     }
 
     @Override
@@ -494,7 +495,7 @@ public class DatasetKeyOutputFormat<E> extends OutputFormat<E, Void> {
   }
 
   private static String getJobDatasetName(JobContext jobContext) {
-    return jobContext.getJobID().toString();
+    return Hadoop.JobContext.getJobID.invoke(jobContext).toString();
   }
 
   private static String getTaskAttemptDatasetName(TaskAttemptContext taskContext) {
@@ -529,11 +530,26 @@ public class DatasetKeyOutputFormat<E> extends OutputFormat<E, Void> {
     return type;
   }
 
+  /**
+   * The job dataset may already exist if the ApplicationMaster was restarted
+   */
   @SuppressWarnings("unchecked")
-  private static <E> Dataset<E> createJobDataset(JobContext jobContext) {
+  private static <E> Dataset<E> loadOrCreateJobDataset(JobContext jobContext) {
     Dataset<Object> dataset = load(jobContext).getDataset();
     String jobDatasetName = getJobDatasetName(jobContext);
     DatasetRepository repo = getDatasetRepository(jobContext);
+    if (repo.exists(TEMP_NAMESPACE, jobDatasetName)) {
+      Dataset<E> tempDataset = repo.load(TEMP_NAMESPACE, jobDatasetName,
+        DatasetKeyOutputFormat.<E>getType(jobContext));
+      try {
+        Compatibility.checkCompatible(dataset.getDescriptor(),
+          tempDataset.getDescriptor());
+        return tempDataset;
+      } catch (RuntimeException ex) {
+        // swallow
+      }
+    }
+
     return repo.create(TEMP_NAMESPACE, jobDatasetName,
         copy(dataset.getDescriptor()),
         DatasetKeyOutputFormat.<E>getType(jobContext));
diff --git a/kite-data/kite-data-mapreduce/src/test/java/org/kitesdk/data/mapreduce/TestMergeOutputCommitter.java b/kite-data/kite-data-mapreduce/src/test/java/org/kitesdk/data/mapreduce/TestMergeOutputCommitter.java
new file mode 100644
index 0000000..5a326a1
--- /dev/null
+++ b/kite-data/kite-data-mapreduce/src/test/java/org/kitesdk/data/mapreduce/TestMergeOutputCommitter.java
@@ -0,0 +1,75 @@
+/*
+ * Copyright 2015 Cloudera, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.kitesdk.data.mapreduce;
+
+import org.apache.avro.generic.GenericData;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.mapreduce.JobContext;
+import org.apache.hadoop.mapreduce.JobID;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+import org.kitesdk.compat.Hadoop;
+import org.kitesdk.data.Dataset;
+import org.kitesdk.data.DatasetDescriptor;
+import org.kitesdk.data.Formats;
+import static org.kitesdk.data.mapreduce.FileSystemTestBase.STATS_SCHEMA;
+import org.kitesdk.data.spi.DefaultConfiguration;
+
+public class TestMergeOutputCommitter extends FileSystemTestBase {
+
+  private Dataset<GenericData.Record> outputDataset;
+
+  public TestMergeOutputCommitter() {
+    super(Formats.AVRO);
+  }
+
+  @Before
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    outputDataset = repo.create("ns", "out",
+      new DatasetDescriptor.Builder()
+      .property("kite.allow.csv", "true")
+      .schema(STATS_SCHEMA)
+      .format(format)
+      .build(), GenericData.Record.class);
+  }
+
+  @After
+  public void tearDown() {
+    repo.delete("ns", "out");
+  }
+
+  @Test
+  public void testSetupJobIsIdempotent() {
+    DatasetKeyOutputFormat.MergeOutputCommitter<Object> outputCommitter
+      = new DatasetKeyOutputFormat.MergeOutputCommitter<Object>();
+
+    Configuration conf = DefaultConfiguration.get();
+    DatasetKeyOutputFormat.configure(conf).appendTo(outputDataset);
+
+    JobID jobId = new JobID("jt", 42);
+    JobContext context = Hadoop.JobContext.ctor.newInstance(conf, jobId);
+
+    // setup the job
+    outputCommitter.setupJob(context);
+
+    // call setup again to simulate an ApplicationMaster restart
+    outputCommitter.setupJob(context);
+  }
+
+}
diff --git a/kite-hadoop-compatibility/src/main/java/org/kitesdk/compat/Hadoop.java b/kite-hadoop-compatibility/src/main/java/org/kitesdk/compat/Hadoop.java
index 5be0b09..47db391 100644
--- a/kite-hadoop-compatibility/src/main/java/org/kitesdk/compat/Hadoop.java
+++ b/kite-hadoop-compatibility/src/main/java/org/kitesdk/compat/Hadoop.java
@@ -17,7 +17,7 @@
 package org.kitesdk.compat;
 
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.mapreduce.TaskAttemptContext;
+import org.apache.hadoop.mapreduce.JobID;
 import org.apache.hadoop.mapreduce.TaskAttemptID;
 
 public class Hadoop {
@@ -35,10 +35,26 @@ public class Hadoop {
   }
 
   public static class JobContext {
+    public static final DynConstructors.
+        Ctor<org.apache.hadoop.mapreduce.JobContext> ctor =
+        new DynConstructors.Builder(org.apache.hadoop.mapreduce.TaskAttemptContext.class)
+            .hiddenImpl(
+                "org.apache.hadoop.mapreduce.task.JobContextImpl",
+                Configuration.class, JobID.class)
+            .hiddenImpl(
+                "org.apache.hadoop.mapreduce.JobContext",
+                Configuration.class, JobID.class)
+            .build();
+
     public static final DynMethods.UnboundMethod getConfiguration =
         new DynMethods.Builder("getConfiguration")
             .impl(org.apache.hadoop.mapreduce.JobContext.class)
             .build();
+
+    public static final DynMethods.UnboundMethod getJobID =
+        new DynMethods.Builder("getJobID")
+            .impl(org.apache.hadoop.mapreduce.JobContext.class)
+            .build();
   }
 
   public static class TaskAttemptContext {
-- 
1.7.9.5

