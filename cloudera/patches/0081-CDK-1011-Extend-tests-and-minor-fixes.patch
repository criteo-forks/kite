From fa254ab36aaaa553d1138457bc447f8399f860a1 Mon Sep 17 00:00:00 2001
From: Ryan Blue <blue@apache.org>
Date: Thu, 11 Jun 2015 10:45:00 -0700
Subject: [PATCH 081/140] CDK-1011: Extend tests and minor fixes.

Conflicts:
	kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandCluster.java
Resolution:
    Removed methods updated for a conflict with the Crunch hash fix.
---
 .../org/kitesdk/data/crunch/CrunchDatasets.java    |    8 +-
 .../org/kitesdk/cli/commands/CompactCommand.java   |    6 +-
 .../java/org/kitesdk/cli/commands/CopyCommand.java |    6 +-
 .../org/kitesdk/cli/commands/TransformCommand.java |    8 ++
 .../java/org/kitesdk/tools/CompactionTask.java     |    4 +-
 .../main/java/org/kitesdk/tools/TransformTask.java |    4 +-
 .../cli/commands/TestCompactCommandCluster.java    |   95 ++++++++++--------
 .../cli/commands/TestCopyCommandCluster.java       |  104 ++++----------------
 ...yCommandClusterChangedNameWithPartitioning.java |   15 ++-
 .../TestCopyCommandClusterSchemaEvolution.java     |    8 --
 10 files changed, 106 insertions(+), 152 deletions(-)

diff --git a/kite-data/kite-data-crunch/src/main/java/org/kitesdk/data/crunch/CrunchDatasets.java b/kite-data/kite-data-crunch/src/main/java/org/kitesdk/data/crunch/CrunchDatasets.java
index e043c0d..1947566 100644
--- a/kite-data/kite-data-crunch/src/main/java/org/kitesdk/data/crunch/CrunchDatasets.java
+++ b/kite-data/kite-data-crunch/src/main/java/org/kitesdk/data/crunch/CrunchDatasets.java
@@ -220,8 +220,7 @@ public class CrunchDatasets {
     //ensure the number of writers is honored whether it is per partition or total.
     DatasetDescriptor descriptor = view.getDataset().getDescriptor();
     if (descriptor.isPartitioned()) {
-      GetStorageKey<E> getKey = new GetStorageKey<E>(view,
-          numPartitionWriters > 0 ? numPartitionWriters : 1);
+      GetStorageKey<E> getKey = new GetStorageKey<E>(view, numPartitionWriters);
       PTable<Pair<GenericData.Record, Integer>, E> table = collection
           .by(getKey, Avros.pairs(Avros.generics(getKey.schema()), Avros.ints()));
       PGroupedTable<Pair<GenericData.Record, Integer>, E> grouped =
@@ -252,7 +251,8 @@ public class CrunchDatasets {
     }
   }
 
-  @edu.umd.cs.findbugs.annotations.SuppressWarnings(value={"SE_NO_SERIALVERSIONID","SE_TRANSIENT_FIELD_NOT_RESTORED"},
+  @edu.umd.cs.findbugs.annotations.SuppressWarnings(
+      value={"SE_NO_SERIALVERSIONID","SE_TRANSIENT_FIELD_NOT_RESTORED"},
       justification="Purposely not supported across versions, fields properly initialized")
   private static class GetStorageKey<E> extends MapFn<E, Pair<GenericData.Record, Integer>> {
     private final String strategyString;
@@ -307,7 +307,7 @@ public class CrunchDatasets {
     @Override
     public Pair<GenericData.Record, Integer> map(E entity) {
       int marker = count % numPartitionWriters;
-      count++;
+      count += 1;
       return Pair.<GenericData.Record, Integer>of(key.reuseFor(entity, provided, accessor), marker);
     }
   }
diff --git a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CompactCommand.java b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CompactCommand.java
index 3b76eff..88ea631 100644
--- a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CompactCommand.java
+++ b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CompactCommand.java
@@ -45,7 +45,7 @@ public class CompactCommand extends BaseDatasetCommand {
 
   @Parameter(names={"--files-per-partition"},
       description="The number of files per partition to create")
-  int numPartitionWriters = -1;
+  int filesPerPartition = -1;
 
   @Override
   public int run() throws IOException {
@@ -68,8 +68,8 @@ public class CompactCommand extends BaseDatasetCommand {
       task.setNumWriters(numWriters);
     }
 
-    if (numPartitionWriters >= 0) {
-      task.setNumPartitionWriters(numPartitionWriters);
+    if (filesPerPartition > 0) {
+      task.setFilesPerPartition(filesPerPartition);
     }
 
     PipelineResult result = task.run();
diff --git a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CopyCommand.java b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CopyCommand.java
index 8ac4bd0..b89d6d7 100644
--- a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CopyCommand.java
+++ b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/CopyCommand.java
@@ -57,7 +57,7 @@ public class CopyCommand extends BaseDatasetCommand {
 
   @Parameter(names={"--files-per-partition"},
       description="The number of files per partition to create")
-  int numPartitionWriters = -1;
+  int filesPerPartition = -1;
 
   @Parameter(
       names={"--overwrite"},
@@ -103,8 +103,8 @@ public class CopyCommand extends BaseDatasetCommand {
       task.setNumWriters(numWriters);
     }
 
-    if (numPartitionWriters >= 0) {
-      task.setNumWriters(numPartitionWriters);
+    if (filesPerPartition > 0) {
+      task.setFilesPerPartition(filesPerPartition);
     }
 
     if (overwrite) {
diff --git a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/TransformCommand.java b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/TransformCommand.java
index 36c5263..e774252 100644
--- a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/TransformCommand.java
+++ b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/cli/commands/TransformCommand.java
@@ -53,6 +53,10 @@ public class TransformCommand extends BaseDatasetCommand {
       description="The number of writer processes to use")
   int numWriters = -1;
 
+  @Parameter(names={"--files-per-partition"},
+      description="The number of files per partition to create")
+  int filesPerPartition = -1;
+
   @Parameter(names={"--transform"},
       description="A transform DoFn class name")
   String transform = null;
@@ -102,6 +106,10 @@ public class TransformCommand extends BaseDatasetCommand {
       task.setNumWriters(numWriters);
     }
 
+    if (filesPerPartition > 0) {
+      task.setFilesPerPartition(filesPerPartition);
+    }
+
     PipelineResult result = task.run();
 
     if (result.succeeded()) {
diff --git a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/CompactionTask.java b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/CompactionTask.java
index 902a180..b3061d3 100644
--- a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/CompactionTask.java
+++ b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/CompactionTask.java
@@ -62,8 +62,8 @@ public class CompactionTask<T> implements Configurable {
     return task.getConf();
   }
 
-  public void setNumPartitionWriters(int numPartitionWriters) {
-    task.setNumPartitionWriters(numPartitionWriters);
+  public void setFilesPerPartition(int filesPerPartition) {
+    task.setFilesPerPartition(filesPerPartition);
   }
 
   @SuppressWarnings("unchecked")
diff --git a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/TransformTask.java b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/TransformTask.java
index c9119bd..6f257a4 100644
--- a/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/TransformTask.java
+++ b/kite-tools-parent/kite-tools/src/main/java/org/kitesdk/tools/TransformTask.java
@@ -96,8 +96,8 @@ public class TransformTask<S, T> extends Configured {
     return this;
   }
 
-  public TransformTask setNumPartitionWriters(int numPartitionWriters) {
-    Preconditions.checkArgument(numPartitionWriters >= 0,
+  public TransformTask setFilesPerPartition(int numPartitionWriters) {
+    Preconditions.checkArgument(numPartitionWriters > 0,
         "Invalid number of partition writers: " + numPartitionWriters);
     this.numPartitionWriters = numPartitionWriters;
     return this;
diff --git a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCompactCommandCluster.java b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCompactCommandCluster.java
index a873de3..b7ac40d 100644
--- a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCompactCommandCluster.java
+++ b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCompactCommandCluster.java
@@ -22,14 +22,15 @@ import com.google.common.io.Files;
 import org.apache.avro.SchemaBuilder;
 import org.apache.avro.generic.GenericData;
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapred.LocalJobRunner;
 import org.apache.hadoop.mapreduce.Job;
 import org.junit.After;
 import org.junit.Assert;
 import org.junit.Assume;
 import org.junit.Before;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
 import org.kitesdk.cli.TestUtil;
 import org.kitesdk.compat.DynMethods;
 import org.kitesdk.compat.Hadoop;
@@ -41,7 +42,6 @@ import org.kitesdk.data.PartitionStrategy;
 import org.kitesdk.data.URIBuilder;
 import org.kitesdk.data.spi.DatasetRepositories;
 import org.kitesdk.data.spi.DatasetRepository;
-import org.kitesdk.data.spi.filesystem.DatasetTestUtilities;
 import org.kitesdk.data.spi.filesystem.FileSystemDataset;
 import org.slf4j.Logger;
 
@@ -56,8 +56,11 @@ import static org.mockito.Mockito.verifyNoMoreInteractions;
 
 public class TestCompactCommandCluster extends MiniDFSTest {
 
-  private static final String source = "users_source";
-  private static final String source_partitioned = "users_source_partitioned";
+  @Rule
+  public final TemporaryFolder temp = new TemporaryFolder();
+
+  private static final String unpartitioned = "users_source";
+  private static final String partitioned = "users_source_partitioned";
   private static final String avsc = "target/user.avsc";
   private static String repoUri;
   private int numRecords;
@@ -65,24 +68,26 @@ public class TestCompactCommandCluster extends MiniDFSTest {
   @Before
   public void createDatasets() throws Exception {
     repoUri = "hdfs://" + getDFS().getUri().getAuthority() + "/tmp/data";
-    TestUtil.run("delete", source, "-r", repoUri, "-d", "target/data");
+    TestUtil.run("delete", unpartitioned, "-r", repoUri, "-d", "target/data");
 
-    String csv = "target/users.csv";
+    File csvFile = temp.newFile("users.csv");
+    csvFile.delete();
+    String csv = csvFile.toString();
     BufferedWriter writer = Files.newWriter(
-        new File(csv), CSVSchemaCommand.SCHEMA_CHARSET);
+        csvFile, CSVSchemaCommand.SCHEMA_CHARSET);
 
     writer.append("id,username,email\n");
-    numRecords = 10;
+    numRecords = 30;
     for(int i = 0; i < numRecords; i++) {
       writer.append(i+",test"+i+",test"+i+"@example.com\n");
     }
     writer.close();
 
     TestUtil.run("-v", "csv-schema", csv, "-o", avsc, "--class", "User");
-    TestUtil.run("create", source, "-s", avsc,
+    TestUtil.run("create", unpartitioned, "-s", avsc,
         "-r", repoUri, "-d", "target/data");
 
-    URI dsUri = URIBuilder.build("repo:" + repoUri, "default", source_partitioned);
+    URI dsUri = URIBuilder.build("repo:" + repoUri, "default", partitioned);
     Datasets.<Object, Dataset<Object>>create(dsUri, new DatasetDescriptor.Builder()
         .partitionStrategy(new PartitionStrategy.Builder()
             .hash("id", 2)
@@ -95,8 +100,8 @@ public class TestCompactCommandCluster extends MiniDFSTest {
         .build(), Object.class);
 
 
-    TestUtil.run("csv-import", csv, source, "-r", repoUri, "-d", "target/data");
-    TestUtil.run("csv-import", csv, source_partitioned, "-r", repoUri, "-d", "target/data");
+    TestUtil.run("csv-import", csv, unpartitioned, "-r", repoUri, "-d", "target/data");
+    TestUtil.run("csv-import", csv, partitioned, "-r", repoUri, "-d", "target/data");
   }
 
   @Before
@@ -108,37 +113,37 @@ public class TestCompactCommandCluster extends MiniDFSTest {
 
   @After
   public void deleteSourceDatasets() throws Exception {
-    TestUtil.run("delete", source, "-r", repoUri, "-d", "target/data");
-    TestUtil.run("delete", source_partitioned, "-r", repoUri, "-d", "target/data");
+    TestUtil.run("delete", unpartitioned, "-r", repoUri, "-d", "target/data");
+    TestUtil.run("delete", partitioned, "-r", repoUri, "-d", "target/data");
   }
 
   private Logger console;
   private CompactCommand command;
 
   @Test
-  public void testBasicCompact() throws Exception {
+  public void testBasicUnpartitionedCompact() throws Exception {
     command.repoURI = repoUri;
-    command.datasets = Lists.newArrayList(source);
+    command.datasets = Lists.newArrayList(unpartitioned);
 
     int rc = command.run();
     Assert.assertEquals("Should return success", 0, rc);
 
     DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
-    int size = DatasetTestUtilities.datasetSize(repo.load("default", source));
+    int size = Iterators.size(repo.load("default", unpartitioned).newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
-    verify(console).info("Compacted {} records in \"{}\"", (long)numRecords, source);
+    verify(console).info("Compacted {} records in \"{}\"", (long)numRecords, unpartitioned);
     verifyNoMoreInteractions(console);
   }
 
   @Test
   @SuppressWarnings("unchecked")
-  public void testCompactWithNumWriters() throws Exception {
+  public void testCompactUnpartitionedWithNumWriters() throws Exception {
     Assume.assumeTrue(setLocalReducerMax(getConfiguration(), 3));
 
     command.repoURI = repoUri;
     command.numWriters = 3;
-    command.datasets = Lists.newArrayList(source);
+    command.datasets = Lists.newArrayList(unpartitioned);
 
     int rc = command.run();
     Assert.assertEquals("Should return success", 0, rc);
@@ -146,26 +151,26 @@ public class TestCompactCommandCluster extends MiniDFSTest {
     DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
     FileSystemDataset<GenericData.Record> ds =
         (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
-            load("default", source);
-    int size = DatasetTestUtilities.datasetSize(ds);
+            load("default", unpartitioned);
+    int size = Iterators.size(ds.newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
     Assert.assertEquals("Should produce 3 files",
         3, Iterators.size(ds.pathIterator()));
 
-    verify(console).info("Compacted {} records in \"{}\"",(long) numRecords, source);
+    verify(console).info("Compacted {} records in \"{}\"",(long) numRecords, unpartitioned);
     verifyNoMoreInteractions(console);
   }
 
   @Test
   @SuppressWarnings("unchecked")
-  public void testCompactWithNumPartitionWriters() throws Exception {
+  public void testCompactUnpartitionedWithNumPartitionWriters() throws Exception {
     Assume.assumeTrue(setLocalReducerMax(getConfiguration(), 3));
 
     command.repoURI = repoUri;
     command.numWriters = 3;
-    command.numPartitionWriters = 4;
-    command.datasets = Lists.newArrayList(source);
+    command.filesPerPartition = 4;
+    command.datasets = Lists.newArrayList(unpartitioned);
 
     int rc = command.run();
     Assert.assertEquals("Should return success", 0, rc);
@@ -173,15 +178,15 @@ public class TestCompactCommandCluster extends MiniDFSTest {
     DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
     FileSystemDataset<GenericData.Record> ds =
         (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
-            load("default", source);
-    int size = DatasetTestUtilities.datasetSize(ds);
+            load("default", unpartitioned);
+    int size = Iterators.size(ds.newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
-    //ignore the numPartitionWriters
+    // ignores numPartitionWriters
     Assert.assertEquals("Should produce 3 files",
         3, Iterators.size(ds.pathIterator()));
 
-    verify(console).info("Compacted {} records in \"{}\"", (long)numRecords, source);
+    verify(console).info("Compacted {} records in \"{}\"", (long)numRecords, unpartitioned);
     verifyNoMoreInteractions(console);
   }
 
@@ -191,8 +196,8 @@ public class TestCompactCommandCluster extends MiniDFSTest {
     Assume.assumeTrue(setLocalReducerMax(getConfiguration(), 2));
     command.repoURI = repoUri;
     command.numWriters = 2;
-    command.numPartitionWriters = 1;
-    command.datasets = Lists.newArrayList(source_partitioned);
+    command.filesPerPartition = 1;
+    command.datasets = Lists.newArrayList(partitioned);
 
     int rc = command.run();
     Assert.assertEquals("Should return success", 0, rc);
@@ -200,24 +205,29 @@ public class TestCompactCommandCluster extends MiniDFSTest {
     DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
     FileSystemDataset<GenericData.Record> ds =
         (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
-            load("default", source_partitioned);
-    int size = DatasetTestUtilities.datasetSize(ds);
+            load("default", partitioned);
+    int size = Iterators.size(ds.newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
     Assert.assertEquals("Should produce 2 partitions", 2, Iterators.size(ds.getCoveringPartitions().iterator()));
+    Assert.assertEquals(
+        "Should produce 2 files: " + Iterators.toString(ds.pathIterator()),
+        2, Iterators.size(ds.pathIterator()));
 
-    verify(console).info("Compacted {} records in \"{}\"", (long) numRecords, source_partitioned);
+    verify(console).info("Compacted {} records in \"{}\"", (long) numRecords, partitioned);
     verifyNoMoreInteractions(console);
   }
 
   @Test
   @SuppressWarnings("unchecked")
   public void testPartitionedCompactWithNumWritersNumFilesPerPartition() throws Exception {
-    Assume.assumeTrue(setLocalReducerMax(getConfiguration(), 5));
+    Assume.assumeTrue(setLocalReducerMax(getConfiguration(), 2));
     command.repoURI = repoUri;
-    command.numWriters = 1;
-    command.numPartitionWriters = 5;
-    command.datasets = Lists.newArrayList(source_partitioned);
+    // if a reducer gets multiple parts of a partition, they will be combined
+    // use more reducers to reduce the likelihood of that case
+    command.numWriters = 10;
+    command.filesPerPartition = 3;
+    command.datasets = Lists.newArrayList(partitioned);
 
     int rc = command.run();
     Assert.assertEquals("Should return success", 0, rc);
@@ -225,13 +235,14 @@ public class TestCompactCommandCluster extends MiniDFSTest {
     DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
     FileSystemDataset<GenericData.Record> ds =
         (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
-            load("default", source_partitioned);
-    int size = DatasetTestUtilities.datasetSize(ds);
+            load("default", partitioned);
+    int size = Iterators.size(ds.newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
     Assert.assertEquals("Should produce 2 partitions", 2, Iterators.size(ds.getCoveringPartitions().iterator()));
+    Assert.assertEquals("Should produce 6 files", 6, Iterators.size(ds.pathIterator()));
 
-    verify(console).info("Compacted {} records in \"{}\"", (long)numRecords, source_partitioned);
+    verify(console).info("Compacted {} records in \"{}\"", (long)numRecords, partitioned);
     verifyNoMoreInteractions(console);
   }
 
diff --git a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandCluster.java b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandCluster.java
index 2c2622d..fd317d0 100644
--- a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandCluster.java
+++ b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandCluster.java
@@ -21,6 +21,7 @@ import com.google.common.collect.Iterators;
 import com.google.common.io.Files;
 import java.io.BufferedWriter;
 import java.io.File;
+import java.io.IOException;
 import java.net.URI;
 import java.util.Arrays;
 import java.util.Map;
@@ -48,7 +49,6 @@ import org.kitesdk.data.PartitionStrategy;
 import org.kitesdk.data.URIBuilder;
 import org.kitesdk.data.spi.DatasetRepositories;
 import org.kitesdk.data.spi.DatasetRepository;
-import org.kitesdk.data.spi.filesystem.DatasetTestUtilities;
 import org.kitesdk.data.spi.filesystem.FileSystemDataset;
 import org.slf4j.Logger;
 
@@ -70,7 +70,7 @@ public class TestCopyCommandCluster extends MiniDFSTest {
     repoUri = "hdfs://" + getDFS().getUri().getAuthority() + "/tmp/data";
     TestUtil.run("delete", source, "-r", repoUri, "-d", "target/data");
 
-    String csv = "target/users.csv";
+    String csv = "/tmp/users.csv";
     BufferedWriter writer = Files.newWriter(
         new File(csv), CSVSchemaCommand.SCHEMA_CHARSET);
     writer.append("id,username,email\n");
@@ -132,7 +132,7 @@ public class TestCopyCommandCluster extends MiniDFSTest {
     Assert.assertEquals("Should return success", 0, rc);
 
     DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
-    int size = DatasetTestUtilities.datasetSize(repo.load("default", dest));
+    int size = Iterators.size(repo.load("default", dest).newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
     verify(console).info("Added {} records to \"{}\"", (long) numRecords, dest);
@@ -156,7 +156,7 @@ public class TestCopyCommandCluster extends MiniDFSTest {
     FileSystemDataset<GenericData.Record> ds =
         (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
             load("default", dest);
-    int size = DatasetTestUtilities.datasetSize(ds);
+    int size = Iterators.size(ds.newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
     Path[] paths = Iterators.toArray(ds.pathIterator(), Path.class);
@@ -187,7 +187,7 @@ public class TestCopyCommandCluster extends MiniDFSTest {
     FileSystemDataset<GenericData.Record> ds =
         (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
             load("default", dest);
-    int size = DatasetTestUtilities.datasetSize(ds);
+    int size = Iterators.size(ds.newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
     Assert.assertEquals("Should produce " + expectedFiles + " files",
@@ -198,13 +198,21 @@ public class TestCopyCommandCluster extends MiniDFSTest {
   }
 
   @Test
-  @SuppressWarnings("unchecked")
   public void testCopyWithNumPartitionWriters() throws Exception {
-    Assume.assumeTrue(setLocalReducerMax(getConfiguration(), 3));
+    // with no partitioning, the number of files per partition is ignored
+    testCopyWithNumPartitionWriters(3, 4, 3);
+  }
+
+  @SuppressWarnings("unchecked")
+  public void testCopyWithNumPartitionWriters(int numWriters,
+                                              int filesPerPartition,
+                                              int expectedFiles)
+      throws IOException {
+    Assume.assumeTrue(setLocalReducerMax(getConfiguration(), numWriters));
 
     command.repoURI = repoUri;
-    command.numWriters = 3;
-    command.numPartitionWriters = 4;
+    command.numWriters = numWriters;
+    command.filesPerPartition = filesPerPartition;
     command.datasets = Lists.newArrayList(source, dest);
 
     int rc = command.run();
@@ -214,11 +222,11 @@ public class TestCopyCommandCluster extends MiniDFSTest {
     FileSystemDataset<GenericData.Record> ds =
         (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
             load("default", dest);
-    int size = DatasetTestUtilities.datasetSize(ds);
+    int size = Iterators.size(ds.newReader());
     Assert.assertEquals("Should contain copied records", numRecords, size);
 
-    Assert.assertEquals("Should produce 4 files",
-        4, Iterators.size(ds.pathIterator()));
+    Assert.assertEquals("Should produce " + expectedFiles + " files",
+        expectedFiles, Iterators.size(ds.pathIterator()));
 
     verify(console).info("Added {} records to \"{}\"", (long) numRecords, dest);
     verifyNoMoreInteractions(console);
@@ -243,76 +251,4 @@ public class TestCopyCommandCluster extends MiniDFSTest {
       return false;
     }
   }
-
-  @Test
-  @SuppressWarnings("unchecked")
-  public void testPartitionedCopyWithNumWriters() throws Exception {
-    command.repoURI = repoUri;
-    command.numWriters = 3;
-    command.datasets = Lists.newArrayList(source, dest_partitioned);
-    URI dsUri = URIBuilder.build("repo:" + repoUri, "default", dest_partitioned);
-    Datasets.<Object, Dataset<Object>>create(dsUri, new DatasetDescriptor.Builder()
-        .partitionStrategy(new PartitionStrategy.Builder()
-            .hash("id", 2)
-            .build())
-        .schema(SchemaBuilder.record("User").fields()
-            .requiredLong("id")
-            .optionalString("username")
-            .optionalString("email")
-            .endRecord())
-        .build(), Object.class);
-
-    int rc = command.run();
-    Assert.assertEquals("Should return success", 0, rc);
-
-    DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
-    FileSystemDataset<GenericData.Record> ds =
-        (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
-            load("default", dest_partitioned);
-    int size = DatasetTestUtilities.datasetSize(ds);
-    Assert.assertEquals("Should contain copied records", numRecords, size);
-
-    Assert.assertEquals("Should produce 2 partitions",
-        2, Iterators.size(ds.pathIterator()));
-
-    verify(console).info("Added {} records to \"{}\"", (long) numRecords, dest_partitioned);
-    verifyNoMoreInteractions(console);
-  }
-
-  @Test
-  @SuppressWarnings("unchecked")
-  public void testPartitionedCopyWithNumWritersNumFilesPerPartition() throws Exception {
-    command.repoURI = repoUri;
-    command.numWriters = 1;
-    command.numPartitionWriters = 5;
-    command.datasets = Lists.newArrayList(source, dest_partitioned);
-    URI dsUri = URIBuilder.build("repo:" + repoUri, "default", dest_partitioned);
-    Datasets.<Object, Dataset<Object>>create(dsUri, new DatasetDescriptor.Builder()
-        .partitionStrategy(new PartitionStrategy.Builder()
-            .hash("id", 2)
-            .build())
-        .schema(SchemaBuilder.record("User").fields()
-            .requiredLong("id")
-            .optionalString("username")
-            .optionalString("email")
-            .endRecord())
-        .build(), Object.class);
-
-    int rc = command.run();
-    Assert.assertEquals("Should return success", 0, rc);
-
-    DatasetRepository repo = DatasetRepositories.repositoryFor("repo:" + repoUri);
-    FileSystemDataset<GenericData.Record> ds =
-        (FileSystemDataset<GenericData.Record>) repo.<GenericData.Record>
-            load("default", dest_partitioned);
-    int size = DatasetTestUtilities.datasetSize(ds);
-    Assert.assertEquals("Should contain copied records", numRecords, size);
-
-    Assert.assertEquals("Should produce 2 partitions",
-        2, Iterators.size(ds.pathIterator()));
-
-    verify(console).info("Added {} records to \"{}\"", (long) numRecords, dest_partitioned);
-    verifyNoMoreInteractions(console);
-  }
-
 }
diff --git a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterChangedNameWithPartitioning.java b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterChangedNameWithPartitioning.java
index cda965c..a44afd6 100644
--- a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterChangedNameWithPartitioning.java
+++ b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterChangedNameWithPartitioning.java
@@ -45,7 +45,7 @@ public class TestCopyCommandClusterChangedNameWithPartitioning extends TestCopyC
   @Override
   public List<String> getExtraCreateArgs() throws Exception {
     PartitionStrategy partitionStrategy = new PartitionStrategy.Builder()
-      .hash("id", "part", 5)
+      .hash("id", "part", 2)
       .build();
 
     FileOutputStream psOut = new FileOutputStream(partitionStrategyJson);
@@ -59,12 +59,19 @@ public class TestCopyCommandClusterChangedNameWithPartitioning extends TestCopyC
 
   @Override
   public void testCopyWithoutCompaction() throws Exception {
-    testCopyWithoutCompaction(5);
+    testCopyWithoutCompaction(2);
   }
 
   @Override
   public void testCopyWithNumWriters() throws Exception {
-    testCopyWithNumWriters(5);
+    testCopyWithNumWriters(2);
+  }
+
+  @Override
+  public void testCopyWithNumPartitionWriters() throws Exception {
+    // 2 partitions and 3 files in each partition
+    // don't use 2 files per partition or the files get messed up because the
+    // file number and partition number happen to align to the same values
+    testCopyWithNumPartitionWriters(10, 3, 6);
   }
-  
 }
diff --git a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterSchemaEvolution.java b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterSchemaEvolution.java
index f56ff2c..d36b8a4 100644
--- a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterSchemaEvolution.java
+++ b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCopyCommandClusterSchemaEvolution.java
@@ -56,14 +56,6 @@ public abstract class TestCopyCommandClusterSchemaEvolution extends TestCopyComm
     command.setConf(new Configuration());
   }
 
-  @Ignore
-  @Override
-  public void testPartitionedCopyWithNumWriters() throws Exception {
-    super.testPartitionedCopyWithNumWriters(); //To change body of generated methods, choose Tools | Templates.
-  }
-
-  
-
   public abstract Schema getEvolvedSchema(Schema original) throws Exception;
 
   public abstract List<String> getExtraCreateArgs() throws Exception;
-- 
1.7.9.5

