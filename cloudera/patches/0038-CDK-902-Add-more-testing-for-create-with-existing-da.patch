From 0d297677f02deb7e2945b692f178bc0ae927ad2a Mon Sep 17 00:00:00 2001
From: Ryan Blue <blue@apache.org>
Date: Thu, 2 Apr 2015 10:42:46 -0700
Subject: [PATCH 038/140] CDK-902: Add more testing for create with existing
 data.

---
 .../data/spi/filesystem/FileSystemDataset.java     |    2 +-
 .../spi/hive/HiveManagedDatasetRepository.java     |    6 +-
 .../org/kitesdk/data/spi/hive/MetaStoreUtil.java   |   32 +++++++++
 .../commands/TestCreateDatasetCommandCluster.java  |   73 ++++++++++++++++++++
 .../TestCreateDatasetWithExistingData.java         |   18 +++++
 5 files changed, 129 insertions(+), 2 deletions(-)

diff --git a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/FileSystemDataset.java b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/FileSystemDataset.java
index 6dfed31..25d3833 100644
--- a/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/FileSystemDataset.java
+++ b/kite-data/kite-data-core/src/main/java/org/kitesdk/data/spi/filesystem/FileSystemDataset.java
@@ -293,7 +293,7 @@ public class FileSystemDataset<E> extends AbstractDataset<E> implements
     return partitions;
   }
 
-  void addExistingPartitions() {
+  public void addExistingPartitions() {
     if (partitionListener != null) {
       for (Path partition : pathIterator()) {
         partitionListener.partitionAdded(namespace, name, partition.toString());
diff --git a/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/HiveManagedDatasetRepository.java b/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/HiveManagedDatasetRepository.java
index 5d4238e..1bbd36a 100644
--- a/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/HiveManagedDatasetRepository.java
+++ b/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/HiveManagedDatasetRepository.java
@@ -25,6 +25,7 @@ import org.kitesdk.data.DatasetDescriptor;
 import org.kitesdk.data.spi.DatasetRepository;
 import org.kitesdk.data.spi.DefaultConfiguration;
 import org.kitesdk.data.spi.MetadataProvider;
+import org.kitesdk.data.spi.filesystem.FileSystemDataset;
 
 /**
  * <p>
@@ -65,10 +66,13 @@ public class HiveManagedDatasetRepository extends HiveAbstractDatasetRepository
   }
 
   @Override
+  @SuppressWarnings("unchecked")
   public <E> Dataset<E> create(String namespace, String name, DatasetDescriptor descriptor) {
     // avoids calling fsRepository.create, which creates the data path
     getMetadataProvider().create(namespace, name, descriptor);
-    return load(namespace, name);
+    FileSystemDataset<E> dataset = (FileSystemDataset<E>) load(namespace, name);
+    dataset.addExistingPartitions();
+    return dataset;
   }
 
   @Override
diff --git a/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/MetaStoreUtil.java b/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/MetaStoreUtil.java
index cf7884e..75e3ed5 100644
--- a/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/MetaStoreUtil.java
+++ b/kite-data/kite-data-hive/src/main/java/org/kitesdk/data/spi/hive/MetaStoreUtil.java
@@ -15,17 +15,21 @@
  */
 package org.kitesdk.data.spi.hive;
 
+import com.google.common.base.Joiner;
 import com.google.common.collect.ImmutableList;
+import com.google.common.collect.Lists;
 import java.util.List;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;
 import org.apache.hadoop.hive.metastore.api.AlreadyExistsException;
 import org.apache.hadoop.hive.metastore.api.Database;
+import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.InvalidObjectException;
 import org.apache.hadoop.hive.metastore.api.InvalidOperationException;
 import org.apache.hadoop.hive.metastore.api.MetaException;
 import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;
+import org.apache.hadoop.hive.metastore.api.Partition;
 import org.apache.hadoop.hive.metastore.api.Table;
 import org.apache.hadoop.hive.metastore.api.UnknownDBException;
 import org.apache.thrift.TException;
@@ -312,6 +316,34 @@ public class MetaStoreUtil {
     }
   }
 
+  public List<String> listPartitions(final String dbName,
+                                     final String tableName,
+                                     final short max) {
+    ClientAction<List<String>> listPartitions =
+        new ClientAction<List<String>>() {
+          @Override
+          public List<String> call() throws TException {
+            List<Partition> partitions =
+                client.listPartitions(dbName, tableName, max);
+            List<String> paths = Lists.newArrayList();
+            for (Partition partition : partitions) {
+              paths.add(partition.getSd().getLocation());
+            }
+            return paths;
+          }
+        };
+    try {
+      return doWithRetry(listPartitions);
+    } catch (NoSuchObjectException e) {
+      return ImmutableList.of();
+    } catch (MetaException e) {
+      throw new DatasetOperationException("Hive MetaStore exception", e);
+    } catch (TException e) {
+      throw new DatasetOperationException(
+          "Exception communicating with the Hive MetaStore", e);
+    }
+  }
+
 
   public boolean exists(String dbName, String tableName) {
     return tableExists(dbName, tableName);
diff --git a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetCommandCluster.java b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetCommandCluster.java
index 79509ff..3eac052 100644
--- a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetCommandCluster.java
+++ b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetCommandCluster.java
@@ -18,22 +18,35 @@ package org.kitesdk.cli.commands;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.io.ByteStreams;
+import com.google.common.io.Closeables;
 import com.google.common.io.Resources;
+import java.io.IOException;
+import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicInteger;
+import org.apache.avro.generic.GenericRecord;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.metastore.api.Table;
+import org.apache.hadoop.hive.ql.metadata.HiveUtils;
+import org.junit.Assert;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
+import org.kitesdk.cli.example.User;
+import org.kitesdk.data.Dataset;
 import org.kitesdk.data.DatasetDescriptor;
+import org.kitesdk.data.DatasetWriter;
+import org.kitesdk.data.Datasets;
 import org.kitesdk.data.MiniDFSTest;
+import org.kitesdk.data.PartitionStrategy;
 import org.kitesdk.data.spi.DatasetRepository;
 import org.kitesdk.data.spi.DefaultConfiguration;
 import org.kitesdk.data.spi.OptionBuilder;
 import org.kitesdk.data.spi.Registration;
 import org.kitesdk.data.spi.URIPattern;
+import org.kitesdk.data.spi.hive.MetaStoreUtil;
 import org.slf4j.Logger;
 
 import static org.mockito.Mockito.contains;
@@ -140,4 +153,64 @@ public class TestCreateDatasetCommandCluster extends MiniDFSTest {
     DefaultConfiguration.set(existing);
   }
 
+  @Test
+  public void testCreateWithExistingDataPartitions() throws IOException {
+    Configuration existing = DefaultConfiguration.get();
+    try {
+      DefaultConfiguration.set(getConfiguration());
+
+      // create a partitioned dataset and add a record
+      DatasetDescriptor descriptor = new DatasetDescriptor.Builder()
+          .schema(User.class)
+          .partitionStrategy(new PartitionStrategy.Builder()
+              .hash("username", 4)
+              .build())
+          .build();
+      Dataset<User> users = Datasets.create(
+          "dataset:hdfs:/tmp/datasets/users", descriptor, User.class);
+      DatasetWriter<User> writer = null;
+      try {
+        writer = users.newWriter();
+        writer.write(new User("test", "test@example.com"));
+      } finally {
+        Closeables.closeQuietly(writer);
+      }
+
+      // remove the dataset's metadata
+      getDFS().delete(new Path("/tmp/datasets/users/.metadata"), true);
+
+      // use the create command to create an external table in Hive
+      Logger console = mock(Logger.class);
+      CreateDatasetCommand create = new CreateDatasetCommand(console);
+      create.setConf(getConfiguration());
+      create.datasets = Lists.newArrayList("dataset:hive:users");
+      create.location = "hdfs:/tmp/datasets/users";
+      create.run();
+
+      // validate the dataset
+      Dataset<GenericRecord> loaded = Datasets.load("dataset:hive:users");
+      Assert.assertNotNull("Should successfully create Hive dataset", loaded);
+      Assert.assertTrue("Should be partitioned",
+          loaded.getDescriptor().isPartitioned());
+      PartitionStrategy expectedStrategy = new PartitionStrategy.Builder()
+          .provided("username_hash", "int")
+          .build();
+      Assert.assertEquals("Should have a provided partition strategy",
+          expectedStrategy, loaded.getDescriptor().getPartitionStrategy());
+
+      MetaStoreUtil meta = new MetaStoreUtil(getConfiguration());
+      List<String> partitions = meta.listPartitions("default", "users", (short) 10);
+      Assert.assertEquals("Table should have a partition",
+          1, partitions.size());
+      Assert.assertTrue("Partition should exist",
+          getDFS().exists(new Path(partitions.get(0))));
+      Assert.assertTrue("Partition should be a partition directory",
+          partitions.get(0).contains("/tmp/datasets/users/username_hash="));
+
+    } finally {
+      Datasets.delete("dataset:hive:users");
+      DefaultConfiguration.set(existing);
+    }
+  }
+
 }
diff --git a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetWithExistingData.java b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetWithExistingData.java
index a6582bf..ad82858 100644
--- a/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetWithExistingData.java
+++ b/kite-tools-parent/kite-tools/src/test/java/org/kitesdk/cli/commands/TestCreateDatasetWithExistingData.java
@@ -37,6 +37,7 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 import org.kitesdk.cli.TestUtil;
 import org.kitesdk.data.Dataset;
+import org.kitesdk.data.DatasetExistsException;
 import org.kitesdk.data.Datasets;
 import org.kitesdk.data.Formats;
 import org.kitesdk.data.LocalFileSystem;
@@ -63,6 +64,8 @@ public class TestCreateDatasetWithExistingData {
       new Path("target/data/users_partitioned/version=1");
   private static final String existingPartitionedURI =
       "dataset:file:target/data/users_partitioned";
+  private static final String sourceDatasetURI =
+      "dataset:file:target/data/users";
   private static Schema USER_SCHEMA;
   private CreateDatasetCommand command = null;
   private Logger console;
@@ -209,6 +212,21 @@ public class TestCreateDatasetWithExistingData {
   }
 
   @Test
+  public void testFailCreateIfDatasetExists() throws Exception {
+    command.datasets = Lists.newArrayList(sourceDatasetURI);
+
+    TestHelpers.assertThrows(
+        "Should fail because the dataset already exists",
+        DatasetExistsException.class, new Callable<Void>() {
+          @Override
+          public Void call() throws IOException {
+            command.run();
+            return null;
+          }
+        });
+  }
+
+  @Test
   public void testCreateFromExistingPartitioned() throws Exception {
     command.datasets = Lists.newArrayList(existingPartitionedURI);
     command.run();
-- 
1.7.9.5

